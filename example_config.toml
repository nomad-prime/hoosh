# Example Hoosh Configuration File

# Default backend to use when none is specified
default_backend = "anthropic"

# Default agent to use when none is specified
# Note: If this agent is not defined in the [agents] section below,
# a warning will be shown with available agents and the system will
# fall back to the first available agent
default_agent = "coder"

# Verbosity level: "quiet", "normal", "verbose", or "debug"
verbosity = "normal"

# Context manager configuration
# Manages conversation context size and token usage
# Note: Both tool_output_truncation and sliding_window are enabled by default
# You only need to specify this section if you want to customize the default values
[context_manager]
max_tokens = 128000                  # Maximum tokens in context window
compression_threshold = 0.80         # When to trigger compression (80% of max_tokens)
preserve_recent_percentage = 0.50    # Percentage of recent messages to keep during compression
warning_threshold = 0.70             # When to warn about token pressure (70% of max_tokens)

# Tool output truncation configuration (enabled by default)
# Reduces token usage by truncating older tool outputs in conversation history
# Omit this section entirely to use defaults, or customize as needed
[context_manager.tool_output_truncation]
max_length = 4000                    # Maximum characters per tool output (default: 4000)
show_truncation_notice = true        # Show "[... truncated N characters ...]" notice (default: true)
smart_truncate = false               # If true, keep head + tail instead of just head (default: false)
head_length = 3000                   # Characters to keep from start (default: 3000, smart_truncate only)
tail_length = 1000                   # Characters to keep from end (default: 1000, smart_truncate only)
preserve_last_tool_result = true     # If false, even the last tool result will be truncated (default: true)
                                     # Set to false if you hit context limits due to large final results

# Sliding window configuration (enabled by default)
# Limits the total number of messages in conversation history to prevent unbounded growth
# Omit this section entirely to use defaults, or customize as needed
[context_manager.sliding_window]
window_size = 40                     # Maximum number of messages to keep (default: 40)
preserve_system = true               # Always keep system messages (default: true, recommended)
preserve_initial_task = true         # Always keep the first user message (default: true, recommended)
min_messages_before_windowing = 50   # Don't apply window until this many messages exist (default: 50)
strict_window_size = false           # If true, enforce window_size as hard limit even when preserving (default: false)
                                     # Set to true if system messages exceed window_size and you need tight limits

# Backend configurations
[backends.anthropic]
api_key = "your-anthropic-api-key-here"
model = "claude-3-5-sonnet-20241022"
temperature = 0.7

[backends.openai]
api_key = "your-openai-api-key-here"
model = "gpt-4o"
temperature = 0.7

[backends.together]
api_key = "your-together-api-key-here"
base_url = "https://api.together.xyz/v1"
model = "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo"
temperature = 0.7

# Agent configurations
# Note: If the default_agent setting above doesn't match any agent defined here,
# a warning will be shown and the system will automatically fall back to the
# first available agent from this list

[agents.coder]
file = "hoosh_coder.txt"
description = "Implements features and writes code"
tags = ["coding", "implementation"]

[agents.planner]
file = "hoosh_planner.txt"
description = "Breaks down complex tasks into actionable steps"
tags = ["planning", "architecture", "strategy"]

[agents.assistant]
file = "hoosh_assistant.txt"
description = "General purpose assistant for answering questions"
tags = ["general", "q&a", "help"]
