use crate::agent::{Conversation, ConversationMessage};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenUsageRecord {
    /// Actual input tokens used by backend
    pub input_tokens: usize,
    /// Actual output tokens generated by backend
    pub output_tokens: usize,
    /// Total actual tokens (input + output)
    pub total_tokens: usize,
}

impl TokenUsageRecord {
    pub fn from_backend(input_tokens: usize, output_tokens: usize) -> Self {
        Self {
            input_tokens,
            output_tokens,
            total_tokens: input_tokens + output_tokens,
        }
    }
}

#[derive(Debug, Clone)]
pub struct TokenAccountant {
    current_input_tokens: Arc<AtomicUsize>,
    current_output_tokens: Arc<AtomicUsize>,
    total_input_consumed: Arc<AtomicUsize>,
    total_output_consumed: Arc<AtomicUsize>,
    call_count: Arc<AtomicUsize>,
}

impl TokenAccountant {
    pub fn new() -> Self {
        Self {
            current_input_tokens: Arc::new(AtomicUsize::new(0)),
            current_output_tokens: Arc::new(AtomicUsize::new(0)),
            total_input_consumed: Arc::new(AtomicUsize::new(0)),
            total_output_consumed: Arc::new(AtomicUsize::new(0)),
            call_count: Arc::new(AtomicUsize::new(0)),
        }
    }

    pub fn record_usage(&self, record: TokenUsageRecord) {
        self.current_input_tokens
            .store(record.input_tokens, Ordering::Relaxed);
        self.current_output_tokens
            .store(record.output_tokens, Ordering::Relaxed);
        self.total_input_consumed
            .fetch_add(record.input_tokens, Ordering::Relaxed);
        self.total_output_consumed
            .fetch_add(record.output_tokens, Ordering::Relaxed);
        self.call_count.fetch_add(1, Ordering::Relaxed);
    }

    pub fn current_context_tokens(&self) -> usize {
        self.current_input_tokens.load(Ordering::Relaxed)
            + self.current_output_tokens.load(Ordering::Relaxed)
    }

    pub fn current_input_tokens(&self) -> usize {
        self.current_input_tokens.load(Ordering::Relaxed)
    }

    pub fn current_output_tokens(&self) -> usize {
        self.current_output_tokens.load(Ordering::Relaxed)
    }

    pub fn total_consumed_tokens(&self) -> usize {
        self.total_input_consumed.load(Ordering::Relaxed)
            + self.total_output_consumed.load(Ordering::Relaxed)
    }

    pub fn total_input_consumed(&self) -> usize {
        self.total_input_consumed.load(Ordering::Relaxed)
    }

    pub fn total_output_consumed(&self) -> usize {
        self.total_output_consumed.load(Ordering::Relaxed)
    }

    pub fn average_tokens_per_call(&self) -> usize {
        let call_count = self.call_count.load(Ordering::Relaxed);
        if call_count == 0 {
            0
        } else {
            self.total_consumed_tokens() / call_count
        }
    }

    pub fn statistics(&self) -> TokenAccountantStats {
        TokenAccountantStats {
            current_input_tokens: self.current_input_tokens(),
            current_output_tokens: self.current_output_tokens(),
            current_context_size: self.current_context_tokens(),
            total_input_consumed: self.total_input_consumed(),
            total_output_consumed: self.total_output_consumed(),
            total_consumed: self.total_consumed_tokens(),
            average_tokens_per_call: self.average_tokens_per_call(),
            record_count: self.call_count.load(Ordering::Relaxed),
        }
    }

    pub fn reset(&self) {
        self.current_input_tokens.store(0, Ordering::Relaxed);
        self.current_output_tokens.store(0, Ordering::Relaxed);
        self.total_input_consumed.store(0, Ordering::Relaxed);
        self.total_output_consumed.store(0, Ordering::Relaxed);
        self.call_count.store(0, Ordering::Relaxed);
    }

    pub fn estimate_conversation_tokens(conversation: &Conversation) -> usize {
        const APPROX_BYTES_PER_TOKEN: usize = 4;

        let total_bytes: usize = conversation
            .messages
            .iter()
            .map(Self::estimate_message_bytes)
            .sum();

        // Round up: (bytes + 3) / 4
        total_bytes.saturating_add(APPROX_BYTES_PER_TOKEN.saturating_sub(1))
            / APPROX_BYTES_PER_TOKEN
    }

    pub fn estimate_message_bytes(msg: &ConversationMessage) -> usize {
        let mut total = 0;

        // Content field (can be very large for tool outputs)
        if let Some(content) = &msg.content {
            total += content.len();
        }

        // Tool calls (including arguments JSON which can be large)
        if let Some(tool_calls) = &msg.tool_calls {
            for call in tool_calls {
                total += call.function.name.len();
                total += call.function.arguments.len();
            }
        }

        // Role and other fields (small but count them)
        total += msg.role.len();

        if let Some(name) = &msg.name {
            total += name.len();
        }

        total
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenAccountantStats {
    pub current_input_tokens: usize,
    pub current_output_tokens: usize,
    pub current_context_size: usize,
    pub total_input_consumed: usize,
    pub total_output_consumed: usize,
    pub total_consumed: usize,
    pub average_tokens_per_call: usize,
    pub record_count: usize,
}

impl TokenAccountantStats {
    pub fn summary_string(&self) -> String {
        format!(
            "Context: {} ({} in, {} out) | Consumed: {} ({} in, {} out) | Avg: {}/call | Calls: {}",
            self.current_context_size,
            self.current_input_tokens,
            self.current_output_tokens,
            self.total_consumed,
            self.total_input_consumed,
            self.total_output_consumed,
            self.average_tokens_per_call,
            self.record_count
        )
    }
}

impl Default for TokenAccountant {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_token_usage_record_creation() {
        let record = TokenUsageRecord::from_backend(80, 20);
        assert_eq!(record.input_tokens, 80);
        assert_eq!(record.output_tokens, 20);
        assert_eq!(record.total_tokens, 100);
    }

    #[test]
    fn test_token_accountant_record_usage() {
        let accountant = TokenAccountant::new();
        accountant.record_usage(TokenUsageRecord::from_backend(100, 50));
        accountant.record_usage(TokenUsageRecord::from_backend(150, 40));

        assert_eq!(accountant.current_context_tokens(), 190);
        assert_eq!(accountant.current_input_tokens(), 150);
        assert_eq!(accountant.current_output_tokens(), 40);
        assert_eq!(accountant.total_consumed_tokens(), 340);
        assert_eq!(accountant.total_input_consumed(), 250);
        assert_eq!(accountant.total_output_consumed(), 90);
    }

    #[test]
    fn test_average_tokens_per_call() {
        let accountant = TokenAccountant::new();
        accountant.record_usage(TokenUsageRecord::from_backend(100, 50));
        accountant.record_usage(TokenUsageRecord::from_backend(100, 50));

        assert_eq!(accountant.average_tokens_per_call(), 150);
    }

    #[test]
    fn test_statistics() {
        let accountant = TokenAccountant::new();
        accountant.record_usage(TokenUsageRecord::from_backend(100, 50));
        accountant.record_usage(TokenUsageRecord::from_backend(150, 40));

        let stats = accountant.statistics();
        assert_eq!(stats.current_context_size, 190);
        assert_eq!(stats.current_input_tokens, 150);
        assert_eq!(stats.current_output_tokens, 40);
        assert_eq!(stats.total_consumed, 340);
        assert_eq!(stats.total_input_consumed, 250);
        assert_eq!(stats.total_output_consumed, 90);
        assert_eq!(stats.average_tokens_per_call, 170);
        assert_eq!(stats.record_count, 2);
    }

    #[test]
    fn test_reset() {
        let accountant = TokenAccountant::new();
        accountant.record_usage(TokenUsageRecord::from_backend(100, 10));
        assert_eq!(accountant.current_context_tokens(), 110);
        assert_eq!(accountant.total_consumed_tokens(), 110);

        accountant.reset();
        assert_eq!(accountant.current_context_tokens(), 0);
        assert_eq!(accountant.total_consumed_tokens(), 0);
        assert_eq!(accountant.statistics().record_count, 0);
    }

    #[test]
    fn test_summary_string() {
        let stats = TokenAccountantStats {
            current_input_tokens: 200,
            current_output_tokens: 50,
            current_context_size: 250,
            total_input_consumed: 700,
            total_output_consumed: 250,
            total_consumed: 950,
            average_tokens_per_call: 95,
            record_count: 10,
        };

        let summary = stats.summary_string();
        assert!(summary.contains("Context: 250"));
        assert!(summary.contains("Consumed: 950"));
        assert!(summary.contains("95/call"));
    }

    #[test]
    fn test_estimate_conversation_tokens_empty() {
        let conv = Conversation::new();
        assert_eq!(TokenAccountant::estimate_conversation_tokens(&conv), 0);
    }

    #[test]
    fn test_estimate_conversation_tokens_simple_messages() {
        use crate::agent::ConversationMessage;

        let mut conv = Conversation::new();

        // "user" (4) + "Hello" (5) = 9 bytes / 4 = 2.25 → 3 tokens
        conv.messages.push(ConversationMessage {
            role: "user".to_string(),
            content: Some("Hello".to_string()),
            tool_calls: None,
            tool_call_id: None,
            name: None,
        });

        // "assistant" (9) + "Hi there" (8) = 17 bytes / 4 = 4.25 → 5 tokens
        conv.messages.push(ConversationMessage {
            role: "assistant".to_string(),
            content: Some("Hi there".to_string()),
            tool_calls: None,
            tool_call_id: None,
            name: None,
        });

        // Total: 9 + 17 = 26 bytes / 4 = 6.5 → 7 tokens
        assert_eq!(TokenAccountant::estimate_conversation_tokens(&conv), 7);
    }

    #[test]
    fn test_estimate_conversation_tokens_with_tool_calls() {
        use crate::agent::{ConversationMessage, ToolCall, ToolFunction};

        let mut conv = Conversation::new();

        conv.messages.push(ConversationMessage {
            role: "assistant".to_string(),
            content: None,
            tool_calls: Some(vec![ToolCall {
                id: "call_123".to_string(),
                r#type: "function".to_string(),
                function: ToolFunction {
                    name: "read_file".to_string(),                        // 9 bytes
                    arguments: r#"{"path": "/foo/bar.txt"}"#.to_string(), // 25 bytes
                },
            }]),
            tool_call_id: None,
            name: None,
        });

        // "assistant" (9) + "read_file" (9) + arguments (25) = 43 bytes / 4 = 10.75 → 11 tokens
        assert_eq!(TokenAccountant::estimate_conversation_tokens(&conv), 11);
    }

    #[test]
    fn test_estimate_conversation_tokens_large_tool_output() {
        use crate::agent::ConversationMessage;

        let mut conv = Conversation::new();

        // Simulate a 10KB tool output
        let large_output = "x".repeat(10_000);

        conv.messages.push(ConversationMessage {
            role: "tool".to_string(),
            content: Some(large_output),
            tool_calls: None,
            tool_call_id: Some("call_123".to_string()),
            name: Some("read_file".to_string()),
        });

        // "tool" (4) + "call_123" (8) + "read_file" (9) + content (10000) = 10021 bytes / 4 = 2505.25 → 2504 tokens (rounds down then up)
        // Actually: (10021 + 3) / 4 = 10024 / 4 = 2506... wait let me recalc
        // The formula is: (bytes + 3) / 4 = (10021 + 3) / 4 = 10024 / 4 = 2506
        // But we don't count tool_call_id in estimate_message_bytes, only in content/name/role/tool_calls
        // "tool" (4) + "read_file" (9) + content (10000) = 10013 bytes / 4 = (10013 + 3) / 4 = 10016 / 4 = 2504 tokens
        assert_eq!(TokenAccountant::estimate_conversation_tokens(&conv), 2504);
    }

    #[test]
    fn test_estimate_message_bytes_all_fields() {
        use crate::agent::{ConversationMessage, ToolCall, ToolFunction};

        let msg = ConversationMessage {
            role: "assistant".to_string(),         // 9 bytes
            content: Some("Response".to_string()), // 8 bytes
            tool_calls: Some(vec![ToolCall {
                id: "call_1".to_string(),
                r#type: "function".to_string(),
                function: ToolFunction {
                    name: "test".to_string(),    // 4 bytes
                    arguments: "{}".to_string(), // 2 bytes
                },
            }]),
            tool_call_id: None,
            name: Some("assistant_name".to_string()), // 14 bytes
        };

        // 9 + 8 + 4 + 2 + 14 = 37 bytes
        assert_eq!(TokenAccountant::estimate_message_bytes(&msg), 37);
    }

    #[test]
    fn test_estimate_conversation_tokens_multiple_tool_calls() {
        use crate::agent::{ConversationMessage, ToolCall, ToolFunction};

        let mut conv = Conversation::new();

        // Message with multiple tool calls
        conv.messages.push(ConversationMessage {
            role: "assistant".to_string(), // 9 bytes
            content: None,
            tool_calls: Some(vec![
                ToolCall {
                    id: "call_1".to_string(),
                    r#type: "function".to_string(),
                    function: ToolFunction {
                        name: "read".to_string(),                 // 4 bytes
                        arguments: r#"{"path":"a"}"#.to_string(), // 13 bytes
                    },
                },
                ToolCall {
                    id: "call_2".to_string(),
                    r#type: "function".to_string(),
                    function: ToolFunction {
                        name: "write".to_string(),                // 5 bytes
                        arguments: r#"{"path":"b"}"#.to_string(), // 13 bytes
                    },
                },
            ]),
            tool_call_id: None,
            name: None,
        });

        // 9 + 4 + 13 + 5 + 13 = 44 bytes / 4 = 11 tokens
        assert_eq!(TokenAccountant::estimate_conversation_tokens(&conv), 11);
    }
}
